#[문제 1] O(n²) 알고리즘의 효율성과 성장률
---
Q. 시간 복잡도가 O(n²)이면, 입력이 작을 때도 항상 느릴까요?
A. 결론부터 말씀드리면, "아니요"입니다.

시간 복잡도가 O(n²)이라고 해서 입력 크기 n이 작을 때 항상 더 느린 것은 아닙니다.
빅오(Big-O) 표기법은 점근적 상한을 나타냅니다.
즉, 입력 크기 n이 아주 커질 때 연산 횟수가 어떻게 증가하는지를 나타내는 지표입니다.
하지만 실제 실행 시간에는 상수 계수나 낮은 차수의 항이 큰 영향을 줍니다.

예시: 작은 입력에서의 역전 현상
두 알고리즘 A와 B가 있다고 가정해 보겠습니다.

알고리즘 A: 연산 횟수 100n (시간 복잡도 O(n))
알고리즘 B: 연산 횟수 2n² (시간 복잡도 O(n²))
만약 입력 크기 n = 10이라면?

A의 연산 횟수: 100 × 10 = 1,000회
B의 연산 횟수: 2 × 100 = 200회
결과: 비록 B가 O(n²)으로 복잡도가 더 높지만, n이 작을 때는 A보다 더 빠르게 실행될 수 있습니다. 따라서 "항상 느리다"는 명제는 틀렸습니다.
---
Q. 그렇다면 왜 빅오를 핵심 척도로 사용하나요? (성장률 관점)
우리가 알고리즘을 분석할 때 가장 중요하게 생각하는 것은 확장성(Scalability)입니다. 즉, 입력 데이터가 무수히 많아졌을 때 성능이 어떻게 변하는가를 봅니다. 
이를 '성장률(Growth Rate)'이라고 합니다.

작은 입력(n): 하드웨어 성능이나 구현 방식(상수항)에 따라 속도 차이가 미미하거나 뒤집힐 수 있습니다.
큰 입력(n): 성장률이 높은 알고리즘은 실행 시간이 기하급수적으로 늘어납니다.

n = 10,000일 때의 비교:
A (O(n)): 1,000,000회 (백만)
B (O(n²)): 200,000,000회 (2억) → 200배 느려짐
핵심: 입력이 커지면 상수나 낮은 차수의 항은 무시할 수 있을 정도로 영향력이 작아지고, 오직 최고 차수(성장률)가 실행 시간을 지배하게 됩니다. 
빅오 표기법은 이 '변화의 추세'를 판단하는 가장 명확한 기준이기 때문에 핵심 척도로 사용됩니다.

#[문제 2] 빅오 표기법과 극한의 개념
Q. 왜 상수 계수와 낮은 차수의 항을 무시하나요?
A. 입력 크기 n이 무한히 커지는 '극한(Limit)'의 상황을 가정하기 때문입니다.
---
1. 극한의 관점에서의 설명
빅오 표기법은 입력 크기 n이 무한대(∞)로 발산할 때의 거동을 설명하는 도구입니다.

주어진 식 3n² + 10n + 5를 예로 들어보겠습니다.

이 식을 가장 높은 차수인 n²으로 나누고, n을 무한대로 보내는 극한을 취해봅니다.

lim(n→∞) (3n² + 10n + 5) / n² = lim(n→∞) (3 + 10/n + 5/n²)

n이 무한히 커지면:
10/n → 0에 수렴 (사라짐)
5/n² → 0에 수렴 (사라짐)
결국 남는 것은 상수 3뿐입니다.
이것이 의미하는 바는, n이 매우 커질 때 전체 식의 값은 오직 n² 항의 변화 추이와 가장 유사하게 움직인다는 것입니다. 
10n이나 5 같은 항들은 n²이 커지는 속도에 비하면 '먼지'와 같이 미미한 존재가 되어버립니다.
---
2. 상수를 무시하는 이유
앞서 남은 상수 3조차도 빅오 표기법에서는 O(n²)이라고 쓸 때 생략합니다.

이유: 알고리즘의 효율성을 '특정 컴퓨터의 성능'이 아니라 '문제 해결 절차의 패턴'으로 분류하고 싶기 때문입니다.
어떤 슈퍼컴퓨터는 처리가 빨라 상수가 작을 수 있고(예: 0.1n²), 느린 컴퓨터는 상수가 클 수 있습니다(예: 100n²).
하지만 데이터가 2배 늘어났을 때 시간이 4배(2²)로 늘어난다는 '경향성(성장률)'은 변하지 않습니다.
이 본질적인 증가 추세만을 남기기 위해 상수 계수와 낮은 차수의 항을 과감히 무시하고 단순화하는 것입니다.

#[문제 3] 시간 복잡도 순서와 대표 예시
실행 시간이 빠른(효율적인) 순서부터 느린(비효율적인) 순서로 나열하면 다음과 같습니다.
---
1. O(1) - 상수 시간 (Constant Time)
설명: 입력 크기 n과 상관없이 항상 일정한 시간이 걸립니다.
예시:
배열의 특정 인덱스 접근 (arr[5])
스택(Stack)의 push / pop 연산
해시 테이블의 조회 (평균적인 경우)
---
2. O(log n) - 로그 시간 (Logarithmic Time)
설명: 입력 크기가 커질수록 처리 시간이 아주 조금씩 늘어납니다. 단계마다 탐색 범위를 절반씩 줄여나가는 경우입니다.
예시:
이진 탐색 (Binary Search)
이진 탐색 트리(BST)에서의 검색 (균형 잡힌 경우)
---
3. O(n) - 선형 시간 (Linear Time)
설명: 입력 크기에 정비례하여 시간이 늘어납니다. 데이터를 처음부터 끝까지 한 번씩 훑어봐야 하는 경우입니다.
예시:
선형 탐색 (Linear Search)
for 문을 사용하여 리스트의 모든 요소 출력하기
---
4. O(n log n) - 선형 로그 시간 (Linearithmic Time)
설명: 선형 시간보다 약간 더 느리지만, 여전히 매우 효율적입니다. 일반적으로 가장 효율적인 정렬 알고리즘들이 여기에 속합니다.
예시:
병합 정렬 (Merge Sort)
퀵 정렬 (Quick Sort) (평균적인 경우)
힙 정렬 (Heap Sort)
---
5. O(n²) - 이차 시간 (Quadratic Time)
설명: 입력 크기의 제곱만큼 시간이 걸립니다. 보통 이중 반복문(for문 안에 for문)을 사용할 때 발생합니다.
예시:
버블 정렬 (Bubble Sort)
선택 정렬 (Selection Sort)
구구단 2단부터 9단까지 출력하기
---
6. O(2ⁿ) - 지수 시간 (Exponential Time)
설명: 데이터가 하나 늘어날 때마다 시간이 2배씩 폭증합니다. n이 조금만 커져도 실행 시간이 감당할 수 없을 정도로 늘어납니다.
예시:
재귀를 이용한 피보나치 수열 (메모이제이션 미사용 시)
외판원 순회 문제(TSP)의 완전 탐색
모든 부분 집합(Subset) 구하기